
import os
import pandas as pd
import streamlit as st
from datetime import datetime
from collections import Counter

LOGS_CSV = "logs/user_activity.csv"
BOOKS_CSV = "data/books_dataset.csv"
USERS_CSV = "data/users_profiles.csv"

def manager_dashboard_full():
    st.header("ğŸ“Š Ù„ÙˆØ­Ø© Ù…Ø¯ÙŠØ± Ù‚Ø³Ù… Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª â€” EDU_AI_LIBRARY (Ø´Ø§Ù…Ù„Ø©)")
    st.caption("ØªØ­Ù„ÙŠÙ„Ø§Øª Ø§Ù„ÙƒØªØ¨ ÙˆØ§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† ÙˆØ§Ù„Ù†Ø´Ø§Ø·")

    if not os.path.exists(LOGS_CSV):
        st.warning("âš ï¸ Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù†Ø´Ø§Ø· Ù…Ø³Ø¬Ù„ Ø¨Ø¹Ø¯.")
        return

    logs = pd.read_csv(LOGS_CSV, names=["name","school","role","question","answer","timestamp"])
    books = pd.read_csv(BOOKS_CSV)
    users = pd.read_csv(USERS_CSV)

    # ğŸ”” ØªÙ†Ø¨ÙŠÙ‡Ø§Øª Ø°ÙƒÙŠØ©
    st.subheader("ğŸ”” Ø§Ù„ØªÙ†Ø¨ÙŠÙ‡Ø§Øª Ø§Ù„Ø°ÙƒÙŠØ©")
    if len(logs) > 0:
        logs["timestamp"] = pd.to_datetime(logs["timestamp"], errors="coerce")
        recent = logs[logs["timestamp"] >= pd.Timestamp.today().normalize() - pd.Timedelta(days=7)]
        if len(recent) > 0:
            st.success(f"ğŸ“ˆ Ù†Ø´Ø§Ø· Ø£Ø³Ø¨ÙˆØ¹ÙŠ: {len(recent)} ØªÙØ§Ø¹Ù„ Ø¬Ø¯ÙŠØ¯ Ø®Ù„Ø§Ù„ Ø¢Ø®Ø± 7 Ø£ÙŠØ§Ù….")
        else:
            st.warning("âš ï¸ Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù†Ø´Ø§Ø· Ø¬Ø¯ÙŠØ¯ Ø®Ù„Ø§Ù„ Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹ Ø§Ù„Ø­Ø§Ù„ÙŠ.")
    else:
        st.info("Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª ÙƒØ§ÙÙŠØ© Ù„Ù„ØªÙ†Ø¨ÙŠÙ‡Ø§Øª.")

    # KPIs
    st.subheader("ğŸ“ˆ Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡")
    c1, c2, c3, c4 = st.columns(4)
    c1.metric("Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ†", len(users))
    c2.metric("Ø¹Ø¯Ø¯ Ø§Ù„ÙƒØªØ¨", len(books))
    c3.metric("Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ø¨Ø­Ø«", len(logs))
    c4.metric("Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ø¯Ø§Ø±Ø³/Ø§Ù„Ø£Ù‚Ø³Ø§Ù…", users["department"].nunique())

    # Ø­Ø§Ù„Ø© Ø§Ù„ÙƒØªØ¨
    st.subheader("ğŸ“š Ø­Ø§Ù„Ø© Ø§Ù„ÙƒØªØ¨")
    if "availability" in books.columns:
        st.bar_chart(books["availability"].value_counts())
    else:
        st.info("Ù„Ù… ÙŠØªÙ… ØªØ­Ø¯ÙŠØ¯ Ø¹Ù…ÙˆØ¯ 'availability' ÙÙŠ Ø§Ù„ÙƒØªØ¨.")

    # Ø§Ù„Ù†Ø´Ø§Ø· Ø­Ø³Ø¨ Ø§Ù„Ø¯ÙˆØ±
    st.subheader("ğŸ‘¥ Ø§Ù„Ù†Ø´Ø§Ø· Ø­Ø³Ø¨ Ø§Ù„Ø¯ÙˆØ±")
    st.bar_chart(logs["role"].value_counts())

    # Ø§Ù„Ù…Ø¯Ø§Ø±Ø³ Ø§Ù„Ø£ÙƒØ«Ø± Ù†Ø´Ø§Ø·Ù‹Ø§
    st.subheader("ğŸ« Ø§Ù„Ù…Ø¯Ø§Ø±Ø³/Ø§Ù„Ø£Ù‚Ø³Ø§Ù… Ø§Ù„Ø£ÙƒØ«Ø± Ù†Ø´Ø§Ø·Ù‹Ø§")
    st.bar_chart(logs["school"].value_counts().head(10))

    # Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø£ÙƒØ«Ø± Ø´ÙŠÙˆØ¹Ù‹Ø§
    st.subheader("ğŸ§  Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø´Ø§Ø¦Ø¹Ø© ÙÙŠ Ø§Ù„Ø£Ø³Ø¦Ù„Ø©")
    all_words = " ".join(logs["question"].dropna().astype(str)).split()
    common = Counter(all_words).most_common(10)
    st.dataframe(pd.DataFrame(common, columns=["Ø§Ù„ÙƒÙ„Ù…Ø©","Ø¹Ø¯Ø¯ Ø§Ù„ØªÙƒØ±Ø§Ø±"]))

    # Ø§Ù„Ù†Ø´Ø§Ø· Ø§Ù„Ø²Ù…Ù†ÙŠ
    st.subheader("â±ï¸ Ø§Ù„Ù†Ø´Ø§Ø· Ø§Ù„Ø²Ù…Ù†ÙŠ")
    if logs["timestamp"].notnull().any():
        logs["date"] = logs["timestamp"].dt.date
        daily = logs.groupby("date").size()
        st.line_chart(daily)

    # Ø§Ù„Ø§Ø³ØªØ¹Ø§Ø±Ø§Øª Ø­Ø³Ø¨ Ø§Ù„Ù…Ø§Ø¯Ø©
    st.subheader("ğŸ“¦ Ø§Ù„Ø§Ø³ØªØ¹Ø§Ø±Ø§Øª/Ø§Ù„Ø§Ù‡ØªÙ…Ø§Ù…Ø§Øª Ø­Ø³Ø¨ Ø§Ù„Ù…Ø§Ø¯Ø©")
    if "subject" in books.columns:
        st.bar_chart(books["subject"].value_counts().head(10))

    # Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙˆÙ† Ø§Ù„Ø£ÙƒØ«Ø± ØªÙØ§Ø¹Ù„Ù‹Ø§
    st.subheader("â­ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙˆÙ† Ø§Ù„Ø£ÙƒØ«Ø± ØªÙØ§Ø¹Ù„Ù‹Ø§")
    st.table(logs["name"].value_counts().head(10))

    # ØªØµØ¯ÙŠØ±
    st.subheader("ğŸ“¤ ØªØµØ¯ÙŠØ± Ø§Ù„ØªÙ‚Ø±ÙŠØ±")
    csv_data = logs.to_csv(index=False)
    st.download_button("ğŸ“¥ ØªØ­Ù…ÙŠÙ„ CSV", csv_data, file_name=f"library_logs_{datetime.now().date()}.csv")

    with st.expander("ğŸ‘ï¸â€ğŸ—¨ï¸ Ø¹Ø±Ø¶ Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"):
        tabA, tabB, tabC = st.tabs(["ğŸ“— Ø§Ù„ÙƒØªØ¨","ğŸ‘¥ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙˆÙ†","ğŸ•“ Ø§Ù„Ø³Ø¬Ù„Ø§Øª"])
        with tabA: st.dataframe(books)
        with tabB: st.dataframe(users)
        with tabC: st.dataframe(logs)
